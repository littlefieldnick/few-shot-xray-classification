{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f535c03-8878-43a5-8846-67ca2493bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415fb8ed-c364-4e25-8644-c927df92512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "device = 'cpu'\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    device = 'cuda'\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a6c43-adc0-458e-9252-4c9ab81d45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"Abdomen\": 0,\n",
    "    \"Ankle\": 1,\n",
    "    \"Cervical Spine\": 2,\n",
    "    \"Chest\": 3,\n",
    "    \"Clavicles\": 4,\n",
    "    \"Elbow\": 5,\n",
    "    \"Feet\": 6,\n",
    "    \"Finger\": 7,\n",
    "    \"Forearm\": 8,\n",
    "    \"Hand\": 9,\n",
    "    \"Hip\": 10, \n",
    "    \"Knee\": 11,\n",
    "    \"Lower Leg\": 12,\n",
    "    \"Lumbar Spine\": 13,\n",
    "    \"Others\": 14,\n",
    "    \"Pelvis\": 15,\n",
    "    \"Shoulder\": 16,\n",
    "    \"Sinus\": 17,\n",
    "    \"Skull\": 18,\n",
    "    \"Thigh\": 19,\n",
    "    \"Thoracic Spine\": 20,\n",
    "    \"Wrist\": 21\n",
    "}\n",
    "\n",
    "\n",
    "class XRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, file_col, lbl_col, text2lbl, transforms=None):\n",
    "        \"\"\"\n",
    "        Initialize Dataset\n",
    "\n",
    "        params:\n",
    "          - csv_file: Path to CSV\n",
    "          - file_col: Column corresponding to file name\n",
    "          - lbl_col: Column corresponding to label column\n",
    "          - text2lbl: Numerical representation of labels\n",
    "          - transforms: Transforms to apply to imgs\n",
    "        \"\"\"\n",
    "\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        self.file_col = file_col\n",
    "        self.lbl_col = lbl_col\n",
    "        self.labels = text2lbl\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of dataset\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get item from dataset\n",
    "\n",
    "        params:\n",
    "          - idx: Index of data record to get.\n",
    "        \"\"\"\n",
    "\n",
    "        img = cv2.imread(self.csv.loc[idx][self.file_col])\n",
    "\n",
    "        img = img.astype(np.float).transpose(2, 1, 0)\n",
    "        label = self.csv.loc[idx][self.lbl_col]\n",
    "\n",
    "        # Convert to tensor and apply transforms\n",
    "        img = torch.from_numpy(img)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04e343-9695-4aec-b1ce-9b4b692495ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet50, inception_v3, efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "def load_and_initalize(model_name, num_classes, extract_features=True):\n",
    "    \"\"\"\n",
    "    Load and initialize a pretrained model. Classification layer of models are set to be trained,\n",
    "    while the rest of the model remains frozen. \n",
    "\n",
    "    params:\n",
    "    - model_name: Pretrained model name to load\n",
    "    - num_classes: Number of classes for the model\n",
    "    - extract_features: Whether or not to extract features from the model\n",
    "    \"\"\"\n",
    "    \n",
    "    input_size = 0\n",
    "    model = None\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        model = resnet18(pretrained=True)\n",
    "\n",
    "        # Extract model features\n",
    "        set_parameter_requires_grad(model, extract_features)\n",
    "\n",
    "        input_size = 224\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = resnet50(pretrained=True)\n",
    "\n",
    "        # Extract model features\n",
    "        set_parameter_requires_grad(model, extract_features)\n",
    "\n",
    "        \n",
    "        input_size = 224\n",
    "   \n",
    "    elif model_name == \"efficientnet-b0\":\n",
    "        model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "        # Extract model features\n",
    "        set_parameter_requires_grad(model, extract_features)\n",
    "\n",
    "        input_size = 224\n",
    "\n",
    "    return model, input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e0199-0298-47c1-833f-8cdfd01162d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, extract_features):\n",
    "    \"\"\"\n",
    "    Extract features from a pretrained model\n",
    "\n",
    "    params:\n",
    "    model -- pretrained model\n",
    "    extract_features -- True or False, indicating whether or not to extract features from model\n",
    "    \"\"\"\n",
    "    if extract_features:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314e7ce-1962-45b5-b030-420a13e9d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/nickolas.littlefield/netstore1/unifesp-x-ray-body-part-classifier/train_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01ce9d-f9a7-47e4-9039-b006d773ec0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bca2ed-5252-4a05-82d3-091e2f5f8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_labels = list(range(0, 22))\n",
    "# class_labels.remove(4)\n",
    "# class_labels.remove(19)\n",
    "# # valid =  np.random.choice(class_labels, size=6, replace=False)\n",
    "# # test = np.random.choice(list(set(class_labels).difference(valid)), size=6, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7415c98-42ab-4e01-8073-14284b637a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fbabc-5d67-49b9-975f-ccddd017b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.array([ 9,  8, 17, 18, 20]) #np.random.choice(class_labels, size=5, replace=False)\n",
    "test = np.array([16, 10,  2,  0, 13])\n",
    "train = np.array([1, 3, 5, 6, 7, 11, 12, 14, 15, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f3f0d-fd06-445c-901e-01febb22a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e04b1f-f4b2-48b3-912a-8a240ec3c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn2learn as l2l\n",
    "from learn2learn.data import MetaDataset, FilteredMetaDataset, TaskDataset\n",
    "\n",
    "img_size = 224\n",
    "transforms_list = transforms.Compose([transforms.Resize((img_size, img_size)), \n",
    "                                 transforms.RandomCrop((img_size, img_size))])\n",
    "valid_transforms_list = transforms.Compose([transforms.Resize((img_size, img_size))])\n",
    "\n",
    "train_meta = FilteredMetaDataset(\n",
    "    XRayDataset(\"/home/nickolas.littlefield/netstore1/unifesp-x-ray-body-part-classifier/train_merged.csv\", \n",
    "                \"fname\", \"Target\", labels, transforms=transforms_list), train\n",
    ")\n",
    "\n",
    "valid_meta = FilteredMetaDataset(\n",
    "    XRayDataset(\"/home/nickolas.littlefield/netstore1/unifesp-x-ray-body-part-classifier/train_merged.csv\", \n",
    "                \"fname\", \"Target\", labels, transforms=valid_transforms_list), valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0cf2d-9833-47e2-8232-adab939cc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn2learn.data import MetaDataset, FilteredMetaDataset, TaskDataset\n",
    "from learn2learn.data.transforms import NWays, KShots, LoadData, RemapLabels\n",
    "from torch.utils.data import DataLoader\n",
    "nway=5\n",
    "shot=5\n",
    "\n",
    "train_query = shot\n",
    "test_query = shot\n",
    "train_transforms = [\n",
    "    NWays(train_meta, nway),\n",
    "    KShots(train_meta, train_query + shot),\n",
    "    LoadData(train_meta),\n",
    "    RemapLabels(train_meta),\n",
    "]\n",
    "train_tasks = l2l.data.TaskDataset(train_meta, task_transforms=train_transforms, num_tasks=1000)\n",
    "# train_loader = DataLoader(train_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "valid_dataset = l2l.data.MetaDataset(valid_meta)\n",
    "valid_transforms = [\n",
    "    NWays(valid_meta, nway),\n",
    "    KShots(valid_meta, test_query + shot),\n",
    "    LoadData(valid_meta),\n",
    "    RemapLabels(valid_meta),\n",
    "]\n",
    "valid_tasks = l2l.data.TaskDataset(valid_dataset,\n",
    "                                   task_transforms=valid_transforms,\n",
    "                                   num_tasks=500)\n",
    "# valid_loader = DataLoader(valid_tasks, pin_memory=True, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1e13a-5071-4eb4-8752-a0ebb98c40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab50da4-63f2-4035-b4ee-d1ba5698faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim, hid_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.__conv_block(x_dim, hid_dim),\n",
    "            self.__conv_block(hid_dim, hid_dim),\n",
    "            self.__conv_block(hid_dim, hid_dim),\n",
    "            self.__conv_block(hid_dim, z_dim)\n",
    "        )\n",
    "\n",
    "    def __conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e9bab-905f-4406-b8c4-e7e4b096aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet, img_size = load_and_initalize(\"resnet18\", num_classes=21, extract_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40419d-e9e4-421c-9a27-4e170979165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PrototypicalNetwork(3, 64, 64).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfbfd6-7c21-40c2-8381-3652148443b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5048d1-d4ae-4649-a9d5-c265188ef7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Taken from https://github.com/learnables/learn2learn/blob/master/examples/vision/protonet_miniimagenet.py\n",
    "def pairwise_distances_logits(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    logits = -((a.unsqueeze(1).expand(n, m, -1) -\n",
    "                b.unsqueeze(0).expand(n, m, -1))**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be549f-ba4e-4efe-a403-65f0f88faa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from: https://github.com/learnables/learn2learn/blob/master/examples/vision/protonet_miniimagenet.py\n",
    "import torch.functional as F\n",
    "def fast_adapt(model, batch, ways, shot, query_num, metric=None, device=None):\n",
    "    if metric is None:\n",
    "        metric = pairwise_distances_logits\n",
    "    if device is None:\n",
    "        device = model.device()\n",
    "    data, labels = batch\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    n_items = shot * ways\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    # Compute support and query embeddings\n",
    "    embeddings = model(data.float())\n",
    "    support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    selection = np.arange(ways) * (shot + query_num)\n",
    "    for offset in range(shot):\n",
    "        support_indices[selection + offset] = True\n",
    "    query_indices = torch.from_numpy(~support_indices)\n",
    "    support_indices = torch.from_numpy(support_indices)\n",
    "    support = embeddings[support_indices].float()\n",
    "    support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "    query = embeddings[query_indices].float()\n",
    "    labels = labels[query_indices].long()\n",
    "\n",
    "    logits = pairwise_distances_logits(query, support)\n",
    "    loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222cb31-4010-4fbb-be94-b168e1891221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79df77-9a6d-4452-87c5-9c6c7dc98bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PrototypicalNetwork(effnet)\n",
    "# model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42f86b-b4dd-4348-9f41-8a41dac4c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dcc72-34ae-4b67-bf07-fc8bdf93e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i in tqdm(range(300)):\n",
    "        batch = train_tasks.sample()\n",
    "\n",
    "        loss, acc = fast_adapt(model,\n",
    "                               batch,\n",
    "                               nway,\n",
    "                               shot,\n",
    "                               train_query,\n",
    "                               metric=pairwise_distances_logits,\n",
    "                               device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    print('epoch {}, train, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "    for i in tqdm(range(100)):\n",
    "        batch = valid_tasks.sample()\n",
    "        loss, acc = fast_adapt(model,\n",
    "                               batch,\n",
    "                               nway,\n",
    "                               shot,\n",
    "                               test_query,\n",
    "                               metric=pairwise_distances_logits,\n",
    "                               device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4f33f-4d48-4be5-ae6e-0c1268391505",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"xray_proto_5shot_5-4-2023.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn2learn",
   "language": "python",
   "name": "few-shot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
